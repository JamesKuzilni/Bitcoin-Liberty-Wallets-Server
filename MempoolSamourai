#!/usr/bin/env python3
import os
import wget
import tarfile
import subprocess
import requests
import shutil

# Install Docker
docker_install_command = ["sudo", "apt", "install", "docker"]
subprocess.run(docker_install_command, check=True)

# Install Docker Compose
docker_compose_install_command = ["sudo", "apt", "install", "docker-compose"]
subprocess.run(docker_compose_install_command, check=True)

# Add current user to the docker group
current_user = os.getlogin()
add_user_to_docker_command = ["sudo", "usermod", "-aG", "docker", current_user]
subprocess.run(add_user_to_docker_command, check=True)

# Make docker-compose executable
docker_compose_chmod_command = ["sudo", "chmod", "+x", "/usr/bin/docker-compose"]
subprocess.run(docker_compose_chmod_command, check=True)

docker_compose_path = "/usr/bin/docker-compose"

if os.access(docker_compose_path, os.X_OK):
    print("Docker Compose is executable.")
else:
    print("Docker Compose is not executable.")

# Define the Git repository URL
repository_url = "https://github.com/mempool/mempool.git"

# Directory where you want to clone the repository
clone_directory = "/home/humble/"

def clone_repository(url, directory):
    try:
        # Run the git clone command
        subprocess.run(["git", "clone", url, directory], check=True)
        print(f"Repository cloned successfully to {directory}")
    except subprocess.CalledProcessError as e:
        print(f"Error cloning the repository: {e}")

if __name__ == "__main__":
    clone_repository(repository_url, clone_directory)

# Define file path, IP address, RPC username, and RPC password
file_path = "/home/humble/mempool/docker/docker-compose.yml"
ipaddress = "your_ip_address"
rpcusername = "your_rpc_username"
rpcpassword = "your_rpc_password"

# Delete the file with sudo privileges
delete_command = ["sudo", "rm", "-f", file_path]

try:
    subprocess.run(delete_command, check=True)
    print(f"File {file_path} deleted successfully.")
except subprocess.CalledProcessError as e:
    print(f"Error deleting file {file_path}: {e}")

# Write the file content to the specified path with sudo privileges
file_content = f'''\
version: "3.7"

services:
  web:
    environment:
      FRONTEND_HTTP_PORT: "8080"
      BACKEND_MAINNET_HTTP_HOST: "api"
    image: mempool/frontend:latest
    user: "1000:1000"
    restart: always
    stop_grace_period: 1m
    command: "./wait-for db:3306 --timeout=720 -- nginx -g 'daemon off;'"
    ports:
      - 4080:8080
  api:
    environment:
      MEMPOOL_BACKEND: "fulcrum"
      CORE_RPC_HOST: "{ipaddress}"
      CORE_RPC_PORT: "8332"
      CORE_RPC_USERNAME: "{rpcusername}"
      CORE_RPC_PASSWORD: "{rpcpassword}"
      DATABASE_ENABLED: "true"
      DATABASE_HOST: "db"
      DATABASE_DATABASE: "mempool"
      DATABASE_USERNAME: "mempool"
      DATABASE_PASSWORD: "mempool"
      STATISTICS_ENABLED: "true"
    image: mempool/backend:latest
    user: "1000:1000"
    restart: always
    stop_grace_period: 1m
    command: "./wait-for-it.sh db:3306 --timeout=720 --strict -- ./start.sh"
    volumes:
      - ./data:/backend/cache
  db:
    environment:
      MYSQL_DATABASE: "mempool"
      MYSQL_USER: "mempool"
      MYSQL_PASSWORD: "mempool"
      MYSQL_ROOT_PASSWORD: "admin"
    image: mariadb:10.5.8
    user: "1000:1000"
    restart: always
    stop_grace_period: 1m
    volumes:
      - ./mysql/data:/var/lib/mysql
'''

# Write the file content to the specified path with sudo privileges
write_command = ["sudo", "tee", file_path]
subprocess.run(write_command, input=file_content.encode(), check=True)

print(f"docker-compose.yml file created at: {file_path}")

# Change current working directory
docker_directory = "/home/humble/mempool/docker/"
os.chdir(docker_directory)

# Command to execute
docker_compose_up_command = ["sudo", "docker-compose", "up"]

try:
    subprocess.run(docker_compose_up_command, check=True)
except subprocess.CalledProcessError as e:
    print(f"Error running 'docker-compose up': {e}")

def download_file(url, filename):
    """Downloads a file from the specified URL to the specified filename."""
    downloads_directory = os.path.join(os.path.expanduser('~'), 'Downloads')
    filepath = os.path.join(downloads_directory, filename)

    print('Downloading file...')
    wget.download(url, filepath)

def extract_file(filename):
    """Extracts a file from a tar archive."""
    filepath = os.path.join(os.path.expanduser('~'), 'Downloads', filename)
    if not os.path.exists(filepath):
        print('File does not exist.')
        return

    with open(filepath, 'rb') as f:
        tar = tarfile.open(fileobj=f)
        tar.extractall(os.path.join(os.path.expanduser('~'), 'Downloads'))

def create_directories():
    """Creates the necessary directories."""
    dojo_app_directory = os.path.join(os.path.expanduser('~'), 'dojo-app')
    os.makedirs(dojo_app_directory, exist_ok=True)

if __name__ == '__main__':
    create_directories()

    url = 'https://code.samourai.io/dojo/samourai-dojo/-/archive/v1.20.0/samourai-dojo-v1.20.0.tar.gz'
    filename = 'samourai-dojo-v1.20.0.tar.gz'

    download_file(url, filename)
    extract_file(filename)

    # Perform the mv command with sudo privileges
    source_directory = os.path.join(os.path.expanduser('~'), 'Downloads', 'samourai-dojo-v1.20.0')
    destination_directory = os.path.join(os.path.expanduser('~'), 'dojo-app')
    subprocess.run(['sudo', 'mv', source_directory, destination_directory])

    print('The file has been downloaded, extracted, and moved to the dojo-app directory.')

def delete_directory(directory):
    """Deletes a directory with sudo privileges."""
    subprocess.run(['sudo', 'rm', '-r', directory])

if __name__ == '__main__':
    dojo_app_directory = os.path.join(os.path.expanduser('~'), 'dojo-app')
    conf_directory = os.path.join(dojo_app_directory, 'samourai-dojo-v1.20.0/docker/my-dojo/conf')

    delete_directory(conf_directory)

    print('The conf directory has been deleted with sudo privileges.')

def create_directory(directory):
    """Creates a directory with sudo privileges."""
    subprocess.run(['sudo', 'mkdir', '-p', directory])

if __name__ == '__main__':
    dojo_app_directory = os.path.join(os.path.expanduser('~'), 'dojo-app')
    conf_directory = os.path.join(dojo_app_directory, 'samourai-dojo-v1.20.0/docker/my-dojo/conf')

    create_directory(conf_directory)

    print('The conf directory has been created with sudo privileges.')
#!/usr/bin/env python3
import os
import subprocess
import random
import string

ipaddress = "10.0.2.15"
rpcusername = "king"
rpcpassword = "bong"

def create_docker_bitcoind_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-bitcoind.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    bitcoind_content = '''\
#########################################
# CONFIGURATION OF BITCOIND CONTAINER
#########################################

# User account used for rpc access to bitcoind
# Type: alphanumeric
BITCOIND_RPC_USER={rpcusername}

# Password of user account used for rpc access to bitcoind
# Type: alphanumeric
BITCOIND_RPC_PASSWORD={rpcpassword}

# Max number of connections to network peers
# Type: integer
BITCOIND_MAX_CONNECTIONS=16

# Mempool maximum size in MB
# Type: integer
BITCOIND_MAX_MEMPOOL=1024

# Db cache size in MB
# Type: integer
BITCOIND_DB_CACHE=1024

# Number of threads to service RPC calls
# Type: integer
BITCOIND_RPC_THREADS=6

# RPC Work queue size
# Type: integer
BITCOIND_RPC_WORK_QUEUE=128

# Mempool expiry in hours
# Defines how long transactions stay in your local mempool before expiring
# Type: integer
BITCOIND_MEMPOOL_EXPIRY=72

# Min relay tx fee in BTC
# Type: numeric
BITCOIND_MIN_RELAY_TX_FEE=0.00001

# Allow incoming connections
# This parameter is inactive if BITCOIND_INSTALL is set to 'off'
# Values: on | off
BITCOIND_LISTEN_MODE=on

#
# EXPERT SETTINGS
#
#
# EPHEMERAL ONION ADDRESS AND BLOOM FILTERS FOR BITCOIND
# THESE PARAMETERS HAVE NO EFFECT IF BITCOIND_INSTALL IS SET TO OFF
#

# Generate a new onion address for bitcoind when Dojo is launched
# Activation of this option is recommended for improved privacy.
# Values: on | off
BITCOIND_EPHEMERAL_HS=on

# Enable bloom filters for other apps to leverage light client mode
# BITCOIND_EPHEMERAL_HS should be set to "off" otherwise new connection will need to be setup after restart
# Values: on | off
BITCOIND_BLOOM_FILTERS=off

#
# EXPOSE BITCOIND RPC API AND ZMQ NOTIFICATIONS TO EXTERNAL APPS
# THESE PARAMETERS HAVE NO EFFECT IF BITCOIND_INSTALL IS SET TO OFF
#
# Expose the RPC API to external apps
# Warning: Do not expose your RPC API to the internet!
# See BITCOIND_RPC_EXTERNAL_IP
# Value: on | off
BITCOIND_RPC_EXTERNAL=off

# IP address used to expose the RPC API to external apps
# This parameter is inactive if BITCOIND_RPC_EXTERNAL isn't set to 'on'
# Warning: Do not expose your RPC API to the internet!
# Recommended value:
#   linux: 127.0.0.1
#   macos or windows: IP address of the VM running the Docker host
# Type: string
BITCOIND_RPC_EXTERNAL_IP=127.0.0.1

#
#
# INSTALL AND RUN BITCOIND INSIDE DOCKER
#

# Install and run bitcoind inside Docker
# Set this option to 'off' to use a bitcoind hosted outside of Docker (not recommended)
# Value: on | off
BITCOIND_INSTALL=off

# IP address of bitcoind used by Dojo
# Set the value to 172.28.1.5 if BITCOIND_INSTALL is set to 'on'
# Type: string
BITCOIND_IP={ipaddress}

# Port of the RPC API
# Set the value to 28256 if BITCOIND_INSTALL is set to 'on'
# Type: integer
BITCOIND_RPC_PORT=8332

# Port exposing ZMQ notifications for raw transactions
# Set the value to 9501 if BITCOIND_INSTALL is set to 'on'
# Type: integer
BITCOIND_ZMQ_RAWTXS=28333

# Port exposing ZMQ notifications for block hashes
# Set value to 9502 if BITCOIND_INSTALL is set to 'on'
# Type: integer
BITCOIND_ZMQ_BLK_HASH=28334


#
# SHUTDOWN
#

# Max delay for bitcoind shutdown (expressed in seconds)
# Defines how long Dojo waits for a clean shutdown of bitcoind before shutting >
# This parameter is inactive if BITCOIND_INSTALL is set to 'off'
# Type: integer
BITCOIND_SHUTDOWN_DELAY=180
'''

    # Use sudo to write the file with elevated privileges
    subprocess.run(['sudo', 'tee', filepath], input=bitcoind_content.format(ipaddress=ipaddress, rpcusername=rpcusername, rpcpassword=rpcpassword), text=True, check=True)

def create_docker_explorer_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-explorer.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    explorer_content = '''\
#########################################
# CONFIGURATION OF EXPLORER CONTAINER
#########################################

# Install and run a block explorer inside Dojo (recommended)
# Value: on | off
EXPLORER_INSTALL=off
'''

    # Use sudo to write the file with elevated privileges
    subprocess.run(['sudo', 'tee', filepath], input=explorer_content, text=True, check=True)

def create_docker_common_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-common.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    common_content = '''\
#
# EXPERT AND DEV SETTINGS
#


#
# NETWORK ENVIRONMENT
#

# Select a Bitcoin network
# Do not modify this value after the first install
# Value: mainnet | testnet
COMMON_BTC_NETWORK=mainnet
'''

    # Use sudo to write the file with elevated privileges
    subprocess.run(['sudo', 'tee', filepath], input=common_content, text=True, check=True)

def create_docker_indexer_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-indexer.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    indexer_content = '''\
#########################################
# CONFIGURATION OF A LOCAL INDEXER
#########################################

# Install and run a local indexer inside Docker
# Set this option to 'off' to use an indexer hosted outside of Docker
# or when using a different data source (local bitcoind, OXT)
# Value: on | off
INDEXER_INSTALL=off

# Choice of the Indexer you would like to install:
# addrindexrs - basic but fast indexer for your Dojo - takes 8-12 hrs to index
# Fulcrum - fast indexer, can be used as Electrum server for personal use - takes 2-3 days to index
# Value: addrindexrs | fulcrum
INDEXER_TYPE=fulcrum

# IP address of the local indexer used by Dojo
# Set the value to 172.28.1.6 if INDEXER_INSTALL is set to 'on'
# Type: string
INDEXER_IP={ipaddress}

# Port of the RPC API
# Set the value to 50001 if INDEXER_INSTALL is set to 'on'
# Type: integer
INDEXER_RPC_PORT=50002

# Support of batch requests by the local indexer
# Set the value to 'active' if INDEXER_TYPE is set to 'fulcrum' or you're using an external Electrum server with RPC batching support
# Value: active | inactive
INDEXER_BATCH_SUPPORT=active

# Choose between TCP and TLS transport when using an external Electrum server
# Value: tcp | tls
INDEXER_PROTOCOL=tls

# Expose the Electrum API to external apps
# Has an effect only if INDEXER_TYPE=fulcrum
# Warning: Do not expose your Electrum API to the internet!
# See INDEXER_EXTERNAL_IP
# Value: on | off
INDEXER_EXTERNAL=off

# IP address used to expose the Electrum API to external apps
# This parameter is inactive if INDEXER_EXTERNAL isn't set to 'on'
# Warning: Do not expose your RPC API to the internet!
# Recommended value:
#   linux: 127.0.0.1
#   macOS or Windows: IP address of the VM running the Docker host
# Type: string
INDEXER_EXTERNAL_IP=127.0.0.1

#
# EXPERT SETTINGS
# (ACTIVE IF INDEXER_INSTALL IS SET TO ON)
#

# Number of blocks to get in one JSONRPC request from bitcoind
# Type: integer
INDEXER_BATCH_SIZE=10

# Total size of block txids to cache (in MB)
# Type: integer
INDEXER_BLK_TXIDS_CACHE_SIZE_MB=10

# Number of transactions to lookup before returning an error
# Type: integer
INDEXER_TXID_LIMIT=501
'''

    # Use sudo to write the file with elevated privileges
    subprocess.run(['sudo', 'tee', filepath], input=indexer_content.format(ipaddress=ipaddress), text=True, check=True)

# Create the configuration files
create_docker_bitcoind_conf()
create_docker_explorer_conf()
create_docker_common_conf()
create_docker_indexer_conf()
def generate_random_password(length):
    characters = string.ascii_letters + string.digits
    password = ''.join(random.choice(characters) for _ in range(length))
    return password

def create_docker_mysql_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-mysql.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    # Generate random passwords
    MYSQL_ROOT_PASSWORD = generate_random_password(12)
    MYSQL_USER = "samourai"
    MYSQL_PASSWORD = generate_random_password(10)

    content = '''\
#########################################
# CONFIGURATION OF MYSQL CONTAINER
#########################################

# Password of MySql root account
# Warning: This option must not be modified after the first installation
# Type: alphanumeric
MYSQL_ROOT_PASSWORD={MYSQL_ROOT_PASSWORD}

# User account used for db access
# Warning: This option must not be modified after the first installation
# Type: alphanumeric
MYSQL_USER={MYSQL_USER}

# Password of user account
# Warning: This option must not be modified after the first installation
# Type: alphanumeric
MYSQL_PASSWORD={MYSQL_PASSWORD}

# MySQL configuration profile
#   default = default configuration parameters
#   low_mem = configuration minimizing the RAM consumed by the database
# Values: default | low_mem
MYSQL_CONF_PROFILE=default
'''

    # Use sudo to write the file with elevated privileges
    command = f'echo "{content.format(MYSQL_ROOT_PASSWORD=MYSQL_ROOT_PASSWORD, MYSQL_USER=MYSQL_USER, MYSQL_PASSWORD=MYSQL_PASSWORD)}" | sudo tee {filepath} > /dev/null'
    subprocess.run(command, shell=True)

# Create the configuration file
create_docker_mysql_conf()

def generate_random_password(length):
    characters = string.ascii_letters + string.digits
    password = ''.join(random.choice(characters) for _ in range(length))
    return password

def create_docker_node_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-node.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    # Generate random passwords
    NODE_API_KEY = generate_random_password(20)
    NODE_ADMIN_KEY = generate_random_password(20)
    NODE_PAYMENT_CODE = generate_random_password(20)
    NODE_JWT_SECRET = generate_random_password(20)

    content = '''\
#########################################
# CONFIGURATION OF NODE JS CONTAINER
#########################################

# API key required for accessing the services provided by the server
# Keep this API key secret!
# Provide a value with a high entropy!
# Type: alphanumeric
NODE_API_KEY={NODE_API_KEY}

# API key required for accessing the admin/maintenance services provided by the server
# Keep this Admin key secret!
# Provide a value with a high entropy!
# Type: alphanumeric
NODE_ADMIN_KEY={NODE_ADMIN_KEY}

# BIP47 Payment Code used for admin authentication
# Type: alphanumeric
NODE_PAYMENT_CODE={NODE_PAYMENT_CODE}

# Secret used by the server for signing Json Web Token
# Keep this value secret!
# Provide a value with a high entropy!
# Type: alphanumeric
NODE_JWT_SECRET={NODE_JWT_SECRET}

# Indexer or third-party service used for imports and rescans of addresses
# Values: local_bitcoind | local_indexer | third_party_explorer
NODE_ACTIVE_INDEXER=local_indexer

# FEE TYPE USED FOR FEES ESTIMATIONS BY BITCOIND
# Allowed values are ECONOMICAL or CONSERVATIVE
NODE_FEE_TYPE=ECONOMICAL
'''

    # Use sudo to write the file with elevated privileges
    command = f'echo "{content.format(NODE_API_KEY=NODE_API_KEY, NODE_ADMIN_KEY=NODE_ADMIN_KEY, NODE_PAYMENT_CODE=NODE_PAYMENT_CODE, NODE_JWT_SECRET=NODE_JWT_SECRET)}" | sudo tee {filepath} > /dev/null'
    subprocess.run(command, shell=True)

# Create the configuration file
create_docker_node_conf()

def create_docker_tor_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-tor.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    content = '''\
#########################################
# CONFIGURATION OF TOR CONTAINER
#########################################

# Port of the Tor Socks proxy
# Type: integer
TOR_SOCKS_PORT=9050

#
# USE TOR BRIDGES
#
# To get Tor bridges head over to https://bridges.torproject.org and click on
# Get bridges, then you will see a form with "Advanced Options" header
# leave the Pluggable Transport as obfs4 and click on Get Bridges button
# solve the captcah, you will get the bridge addresses (usually 3)
#
# Then, set TOR_USE_BRIDGES to "on" and initialize the TOR_BRIDGE_n options
# with the 3 lines generated by the online tool.
#
# For instance, if the first line generated by the tool is:
#   obfs4 24.106.248.94:65531 B9EFBC5... cert=yrX... iat-mode=0
# You will have to set:
#   TOR_BRIDGE_1="obfs4 24.106.248.94:65531 B9EFBC5... cert=yrX... iat-mode=0"
#
# Activate the use of Tor bridges
# Value: on | off
TOR_USE_BRIDGES=off

# Bridge 1
TOR_BRIDGE_1=ToBeDefined

# Bridge 2
TOR_BRIDGE_2=ToBeDefined

# Bridge 3
TOR_BRIDGE_3=ToBeDefined
'''

    # Use sudo to write the file with elevated privileges
    command = f'echo "{content}" | sudo tee {filepath} > /dev/null'
    subprocess.run(command, shell=True)

# Create the configuration file
create_docker_tor_conf()

def create_docker_whirlpool_conf():
    conf_directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my-dojo/conf')
    filename = 'docker-whirlpool.conf.tpl'
    filepath = os.path.join(conf_directory, filename)

    content = '''\
#########################################
# CONFIGURATION OF WHIRLPOOL CONTAINER
#########################################

# Install and run an instance of whirlpool-cli inside Docker
# Value: on | off
WHIRLPOOL_INSTALL=off

# Resynchronize mix counters on startup (startup will be slower)
# Value: on | off
WHIRLPOOL_RESYNC=off

# Contact coordinator through its onion address or clearnet address
# Set to on for onion address, set to off for clearnet address
# Value: on | off
WHIRLPOOL_COORDINATOR_ONION=on

#
# EXPERT SETTINGS
#

# Activate debug logs
# Value: on | off
WHIRLPOOL_DEBUG=off

# Activate more debug logs
# Value: on | off
WHIRLPOOL_DEBUG_CLIENT=off
'''

    # Use sudo to write the file with elevated privileges
    command = f'echo "{content}" | sudo tee {filepath} > /dev/null'
    subprocess.run(command, shell=True)

# Create the configuration file
create_docker_whirlpool_conf()

def run_dojo_install():
    directory = os.path.expanduser('~/dojo-app/samourai-dojo-v1.20.0/docker/my->
    command = './dojo.sh install'

    # Use sudo to execute the command with elevated privileges
    subprocess.run(['sudo', '-E', 'bash', '-c', command], cwd=directory)

# Run the dojo.sh install command
run_dojo_install()

